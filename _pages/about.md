---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

Hello! I‚Äôm Peng Zheng (or ÈÉëÈπè, in Chinese), currently pursuing my second year of graduate studies at Jilin University. Currently, I am a member of the [Intelligent Content Learning (ICL)](https://ruim-jlu.github.io/team) group within the School of Artificial Intelligence at Jilin University. My research interests lie in generative models and neural radiance fields (NeRF).

I have the privilege of being advised by Associate Professor [Rui Ma](https://ruim-jlu.github.io). My journey in the field of artificial intelligence has been exciting, and I‚Äôm passionate about exploring novel ways to create and understand visual content.

Feel free to connect with me or explore my work further! üòä


# üî• News
- *2024.03*: Create my homepage. 

# üìù Publications 

<div class='paper-box'>

  <div class='paper-box-image'>
    <div><div class="badge">arXiv2024</div><img src='images/semantichumanhd.png' alt="sym" width="500"></div>
  </div>
  <div class='paper-box-text' markdown="1">

  [SemanticHuman-HD: High-Resolution Semantic Disentangled 3D Human Generation](https://pengzheng0707.github.io/SemanticHuman-HD/)

  **Peng Zheng**, Tao Liu, Zili Yi, Rui Ma

  - We introduce SemanticHuman-HD, the first method to achieve semantic disentangled human image synthesis. Notably, SemanticHuman-HD is also the first method to achieve 3D-aware image synthesis at 10242 resolution, benefiting from our proposed 3D-aware super-resolution module.
  </div>
</div>

<div class='paper-box'>
<div class='paper-box-image'><div><div class="badge">arXiv2024</div><img src='images/3dssg.png' alt="sym" width="500"></div></div>
<div class='paper-box-text' markdown="1">

[3D-SSGAN: Lifting 2D Semantics for 3D-Aware Compositional Portrait Synthesis](https://arxiv.org/abs/2401.03764)

<style>
  .co-first-author::after {
    content: '*';
    color: red;
  }
</style>

Ruiqi Liu<span class="co-first-author"></span>, **Peng Zheng**<span class="co-first-author"></span>, Ye Wang, Rui Ma

- We propose 3D-SSGAN, a novel framework for 3D-aware compositional portrait image synthesis. First, a simple yet effective depth-guided 2D-to-3D lifting module maps the generated 2D part features and semantics to 3D. Then, a volume renderer with a novel 3D-aware semantic mask renderer is utilized to produce the composed face features and corresponding masks. 
</div>
</div>

<div class='paper-box'>
<div class='paper-box-image'><div><div class="badge">arXiv2024</div><img src='images/taylor.png' alt="sym" width="500"></div></div>
<div class='paper-box-text' markdown="1">

[TaylorGrid: Towards Fast and High-Quality Implicit Field Learning via Direct Taylor-based Grid Optimization](https://arxiv.org/abs/2402.14415)

Renyi Mao, Qingshan Xu, **Peng Zheng**, Ye Wang, Tieru Wu, Rui Ma

- In this paper, we aim for both fast and high-quality implicit field learning, and propose TaylorGrid, a novel implicit field representation which can be efficiently computed via direct Taylor expansion optimization on 2D or 3D grids. 
</div>

</div>


# üéñ Honors and Awards
- *2023:* Received a third prize in the Second Jittor Artificial Intelligence Competition. 

# üìñ Educations
- *2022.09 - 2025.06*, M.S., Jilin University, Computer Science and Technology.
- *2018.09 - 2022.06*, B.S., Jilin University, Agricultural Mechanization and Automation.
